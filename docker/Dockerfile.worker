# =============================================================================
# TRITON WORKER DOCKERFILE (CPU-only, Thin Workers)
# =============================================================================
#
# Lightweight CPU workers that process jobs by calling Triton Inference Server.
# These workers pull jobs from Pub/Sub, call Triton via gRPC, and update job status.
#
# Build:
#   docker build -f docker/Dockerfile.worker -t imagen-triton-worker .
#
# Run with model type:
#   docker run -e MODEL_NAME=upscale -e TRITON_URL=triton:8001 imagen-triton-worker
#   docker run -e MODEL_NAME=enhance -e TRITON_URL=triton:8001 imagen-triton-worker
#   docker run -e MODEL_NAME=style_comic -e TRITON_URL=triton:8001 imagen-triton-worker
#   docker run -e MODEL_NAME=style_aged -e TRITON_URL=triton:8001 imagen-triton-worker
#   docker run -e MODEL_NAME=background_remove -e TRITON_URL=triton:8001 imagen-triton-worker
#
# All workers use the same code (src/workers/triton_worker.py) and communicate
# with the centralized Triton Inference Server for GPU inference.
#
# =============================================================================

FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy dependency files
COPY pyproject.toml .

# Install Python dependencies
RUN pip install --no-cache-dir .

# Copy source code
COPY src/ src/

# =============================================================================
# WORKER CONFIGURATION
# =============================================================================
# Model name (required at runtime)
ENV MODEL_NAME=""

# Triton server URL (required at runtime)
ENV TRITON_URL=""

# =============================================================================
# ENVIRONMENT
# =============================================================================
ENV PYTHONUNBUFFERED=1

# =============================================================================
# HEALTH CHECK
# =============================================================================
# Workers don't have HTTP endpoints, so we check if the process is running
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD pgrep -f "python -m src.workers.triton_worker" || exit 1

# =============================================================================
# ENTRYPOINT
# =============================================================================
# Run the Triton worker with the specified model
# Requires MODEL_NAME and TRITON_URL environment variables at runtime
CMD python -m src.workers.triton_worker
