# =============================================================================
# LOCAL DEVELOPMENT - DOCKER COMPOSE (TRITON ARCHITECTURE)
# =============================================================================
#
# This compose file implements the Triton-based architecture used in production.
#
# Architecture:
#   - 1 Triton Inference Server (GPU) serves all 5 models
#   - 5 CPU-only thin workers call Triton via gRPC
#   - ~60-80% cost savings vs old 5-GPU-worker approach
#
# Usage:
#   docker compose up                    # Start all infrastructure
#   docker compose --profile triton up   # Add Triton (requires NVIDIA GPU)
#   docker compose --profile workers up  # Add thin workers
#   docker compose --profile all up      # Everything (requires GPU)
#
# Without GPU (API development only):
#   docker compose up api redis minio pubsub firestore
#
# =============================================================================

services:
  # ===========================================================================
  # API
  # ===========================================================================
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.api
    ports:
      - "8000:8000"
    environment:
      - DEBUG=true
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT:-local-dev}
      - GCS_BUCKET=${GCS_BUCKET:-local-bucket}
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - FIRESTORE_EMULATOR_HOST=firestore:8080
      - STORAGE_EMULATOR_HOST=http://minio:9000
      # OpenTelemetry
      - OTEL_ENABLED=true
      - OTEL_SERVICE_NAME=imagen-api
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_EXPORTER_CONSOLE=false
      - OTEL_EXPORTER_GCP_TRACE=false
    volumes:
      - ../src:/app/src:ro
    depends_on:
      - redis
      - pubsub
      - jaeger
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # TRITON INFERENCE SERVER (requires NVIDIA GPU)
  # ===========================================================================
  triton:
    build:
      context: ..
      dockerfile: triton/Dockerfile
    profiles:
      - triton
      - all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - "8001:8001"  # gRPC
      - "8000:8000"  # HTTP
      - "8002:8002"  # Metrics
    environment:
      - HF_HOME=/models/huggingface
      - TRANSFORMERS_CACHE=/models/huggingface
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - models:/models/huggingface
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 2147483648  # 2GB shared memory
    command:
      - tritonserver
      - --model-repository=/models/repository
      - --log-verbose=1
      - --log-info=true
      - --metrics-port=8002
      - --allow-metrics=true
      - --strict-model-config=false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s  # Models take time to load

  # ===========================================================================
  # THIN WORKERS (CPU-only, call Triton via gRPC)
  # ===========================================================================
  upscale-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    profiles:
      - workers
      - all
    environment:
      - MODEL_NAME=upscale
      - TRITON_URL=triton:8001
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT:-local-dev}
      - GCS_BUCKET=${GCS_BUCKET:-local-bucket}
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - FIRESTORE_EMULATOR_HOST=firestore:8080
      - STORAGE_EMULATOR_HOST=http://minio:9000
      - PUBSUB_SUBSCRIPTION_UPSCALE=upscale-sub
      # OpenTelemetry
      - OTEL_ENABLED=true
      - OTEL_SERVICE_NAME=imagen-worker-upscale
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_EXPORTER_CONSOLE=false
    depends_on:
      - redis
      - pubsub
      - triton

  enhance-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    profiles:
      - workers
      - all
    environment:
      - MODEL_NAME=enhance
      - TRITON_URL=triton:8001
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT:-local-dev}
      - GCS_BUCKET=${GCS_BUCKET:-local-bucket}
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - FIRESTORE_EMULATOR_HOST=firestore:8080
      - STORAGE_EMULATOR_HOST=http://minio:9000
      - PUBSUB_SUBSCRIPTION_ENHANCE=enhance-sub
      # OpenTelemetry
      - OTEL_ENABLED=true
      - OTEL_SERVICE_NAME=imagen-worker-enhance
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_EXPORTER_CONSOLE=false
    depends_on:
      - redis
      - pubsub
      - triton

  comic-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    profiles:
      - workers
      - all
    environment:
      - MODEL_NAME=style_comic
      - TRITON_URL=triton:8001
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT:-local-dev}
      - GCS_BUCKET=${GCS_BUCKET:-local-bucket}
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - FIRESTORE_EMULATOR_HOST=firestore:8080
      - STORAGE_EMULATOR_HOST=http://minio:9000
      - PUBSUB_SUBSCRIPTION_COMIC=comic-sub
      # OpenTelemetry
      - OTEL_ENABLED=true
      - OTEL_SERVICE_NAME=imagen-worker-comic
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_EXPORTER_CONSOLE=false
    depends_on:
      - redis
      - pubsub
      - triton

  style-aged-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    profiles:
      - workers
      - all
    environment:
      - MODEL_NAME=style_aged
      - TRITON_URL=triton:8001
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT:-local-dev}
      - GCS_BUCKET=${GCS_BUCKET:-local-bucket}
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - FIRESTORE_EMULATOR_HOST=firestore:8080
      - STORAGE_EMULATOR_HOST=http://minio:9000
      - PUBSUB_SUBSCRIPTION_AGED=aged-sub
      # OpenTelemetry
      - OTEL_ENABLED=true
      - OTEL_SERVICE_NAME=imagen-worker-aged
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_EXPORTER_CONSOLE=false
    depends_on:
      - redis
      - pubsub
      - triton

  background-remove-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    profiles:
      - workers
      - all
    environment:
      - MODEL_NAME=background_remove
      - TRITON_URL=triton:8001
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT:-local-dev}
      - GCS_BUCKET=${GCS_BUCKET:-local-bucket}
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - FIRESTORE_EMULATOR_HOST=firestore:8080
      - STORAGE_EMULATOR_HOST=http://minio:9000
      - PUBSUB_SUBSCRIPTION_BACKGROUND_REMOVE=background-remove-sub
      # OpenTelemetry
      - OTEL_ENABLED=true
      - OTEL_SERVICE_NAME=imagen-worker-background-remove
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_EXPORTER_CONSOLE=false
    depends_on:
      - redis
      - pubsub
      - triton

  # ===========================================================================
  # INFRASTRUCTURE (Local Emulators)
  # ===========================================================================
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Pub/Sub emulator
  pubsub:
    image: gcr.io/google.com/cloudsdktool/cloud-sdk:emulators
    command: gcloud beta emulators pubsub start --host-port=0.0.0.0:8085
    ports:
      - "8085:8085"

  # Firestore emulator
  firestore:
    image: gcr.io/google.com/cloudsdktool/cloud-sdk:emulators
    command: gcloud beta emulators firestore start --host-port=0.0.0.0:8080
    ports:
      - "8080:8080"

  # MinIO (S3-compatible storage, replaces GCS locally)
  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # OBSERVABILITY (Jaeger for tracing)
  # ===========================================================================
  jaeger:
    image: jaegertracing/all-in-one:1.52
    ports:
      - "16686:16686"  # Jaeger UI
      - "4317:4317"    # OTLP gRPC receiver
      - "4318:4318"    # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 3

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  models:
    name: imagen-models
  redis-data:
  minio-data:
