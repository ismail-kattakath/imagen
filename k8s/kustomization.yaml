# =============================================================================
# BASE KUSTOMIZATION - TRITON ARCHITECTURE
# =============================================================================
#
# This configuration uses:
# - Triton Inference Server for GPU inference (centralized)
# - Workers for job processing (CPU-only, calls Triton via gRPC)
#
# For manual deployment, use overlays:
#   kubectl apply -k k8s/overlays/dev
#   kubectl apply -k k8s/overlays/prod
#
# =============================================================================

apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - base
  - triton
  - workers
  - autoscaling
  - monitoring
  - network-policies

namespace: imagen
